{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_doc_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "215ef97e259c49ee9ff3f9597b431b68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c147c30be59463ab6608c2e896c3803",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_37b98f472ad0467fabd2a769603dcc70",
              "IPY_MODEL_0bef88434aba48f29040dd8bc5e6e0f1"
            ]
          }
        },
        "2c147c30be59463ab6608c2e896c3803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37b98f472ad0467fabd2a769603dcc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8c0701de67c40e2a6616ae3c247486c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1e9edd03a044ae39b047669a2e9f623"
          }
        },
        "0bef88434aba48f29040dd8bc5e6e0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f5dd4547a71423ca22bab6ea3e21b11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 745kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4646f3eda2d34c4d92dca330d912f147"
          }
        },
        "c8c0701de67c40e2a6616ae3c247486c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1e9edd03a044ae39b047669a2e9f623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f5dd4547a71423ca22bab6ea3e21b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4646f3eda2d34c4d92dca330d912f147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeG6OKTJh5Em",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d23e179b-5ba6-4aa5-9c13-4af394f23c60"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get GPU device name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAtsZNZFiV6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1423185d-0b9b-4a7a-9c05-39611f34ea99"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  # Tell Pytorch to use the GPU\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "  print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHeNlM3ijGGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRHA080xjMF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "import os\n",
        "\n",
        "if not os.path.exists('./data/'):\n",
        "  os.mkdir('./data/')\n",
        "\n",
        "files = [\n",
        "         ('./data/attack_annotated_comments.tsv', 'https://ndownloader.figshare.com/files/7554634'),\n",
        "         ('./data/attack_annotations.tsv',        'https://ndownloader.figshare.com/files/7554637')\n",
        "]\n",
        "\n",
        "for (filename, url) in files:\n",
        "  if not os.path.exists(filename):\n",
        "    print('Downloading:', filename)\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "    print('Done!')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wt2TtAYkmKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "59e53462-3c2b-43fc-af9f-af8eb71b5517"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print('Parsing the dataset .tsv file...')\n",
        "comments = pd.read_csv('./data/attack_annotated_comments.tsv', sep='\\t', index_col=0)\n",
        "annotations = pd.read_csv('./data/attack_annotations.tsv', sep='\\t')\n",
        "print('Done!')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing the dataset .tsv file...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kWCIzCnlB_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "dacd1640-208c-4676-8b41-c7b7011d6710"
      },
      "source": [
        "comments.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>year</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>ns</th>\n",
              "      <th>sample</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rev_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37675</th>\n",
              "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44816</th>\n",
              "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49851</th>\n",
              "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89320</th>\n",
              "      <td>Next, maybe you could work on being less cond...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93890</th>\n",
              "      <td>This page will need disambiguation.</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  comment  year  ...  sample  split\n",
              "rev_id                                                           ...               \n",
              "37675   `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002  ...  random  train\n",
              "44816   `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002  ...  random  train\n",
              "49851   NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002  ...  random  train\n",
              "89320    Next, maybe you could work on being less cond...  2002  ...  random    dev\n",
              "93890                This page will need disambiguation.   2002  ...  random  train\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrpHB65RlIvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "36ddc08f-38e7-4e02-aa07-cdfd7d45f1b0"
      },
      "source": [
        "comments[['comment', 'split']].groupby('split').count()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dev</th>\n",
              "      <td>23160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>23178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>69526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       comment\n",
              "split         \n",
              "dev      23160\n",
              "test     23178\n",
              "train    69526"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9IXj22klP_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create labels and join them with comments\n",
        "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5\n",
        "\n",
        "comments['attack'] = labels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkX8he6Xnov3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comments['comment'] = comments['comment'].apply(lambda x: x.replace('NEWLINE_TOKEN', ' '))\n",
        "comments['comment'] = comments['comment'].apply(lambda x: x.replace('TAB_TOKEN', ' '))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHzbkRrun9F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_comments = comments.query(\"split=='train'\")\n",
        "test_comments = comments.query(\"split=='test'\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPwJJnUXoS6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f707cb8c-e03f-4810-d185-138f4d6f6546"
      },
      "source": [
        "import textwrap\n",
        "import random\n",
        "\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "\n",
        "attack_examples = train_comments.query('attack')['comment']\n",
        "\n",
        "for i in range(10):\n",
        "  j = random.choice(attack_examples.index)\n",
        "\n",
        "  print('')\n",
        "  print(wrapper.fill(attack_examples[j]))\n",
        "  print('')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ::::JUDENSCWEIN TO THE OVENS !  LIARS ! ALL OF YOU !\n",
            "\n",
            "\n",
            "  :: Go Fuck yourself Shell, I couldn't care less what a fucked up waste of\n",
            "space like you thinks. Since when could an editor not edit articles on\n",
            "Wikipedia? It seems you need to kiss a lot of arseholes to make a difference\n",
            "here now.\n",
            "\n",
            "\n",
            "  who died and made you god\n",
            "\n",
            "\n",
            "  == Don't hide the incriminating photographs you Nazi Americans!!!!!! ==  If\n",
            "the photos are graphic its because the horrible deeds committed by the\n",
            "deranges,sadistic perverted soldiers are also equally disturing.I think the\n",
            "Yanks should stop trying to cover up these issues.\n",
            "\n",
            "\n",
            "  go fuck yourself you fucking bitch\n",
            "\n",
            "\n",
            " Anal leakage ban hammer?\n",
            "\n",
            "\n",
            "`== Wonderfull... this lesbian feminist ``nontheist christian`` ``fisherqueen``\n",
            "still moderates wikipedia... == They should ban such feeble brain vertebrates\n",
            "like her from public life. Or she should get a husband and listen to him\n",
            "carefuly  it would mitigate the damage which she does in society. The less you\n",
            "do, the more are you useful, Fisherqueen!   `\n",
            "\n",
            "\n",
            "  butt butt butt butt butt butt butt butt butt butt butt butt butt butt butt\n",
            "butt butt butt butt butt vbutt vbutt butt v v butt v butt butt butt vbutt vbutt\n",
            "\n",
            "\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER   WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER   WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER   WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER   WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER   WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER   WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER   WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER   WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER   WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER  WANKER\n",
            "\n",
            "\n",
            "Who do you think you are with your futile attempts at censorship? Are you a\n",
            "Communist? Do you believe in freedom of speech? If you'd have performed like\n",
            "this during Kennedy's administration, you'd have been paid a visit by a sniper\n",
            "whose middle name would have been mentioned. Spend more time building a Tornado\n",
            "shelter and stocking up with mineral water and Maize and less time irritating\n",
            "me.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHVavFsBqWT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "215ef97e259c49ee9ff3f9597b431b68",
            "2c147c30be59463ab6608c2e896c3803",
            "37b98f472ad0467fabd2a769603dcc70",
            "0bef88434aba48f29040dd8bc5e6e0f1",
            "c8c0701de67c40e2a6616ae3c247486c",
            "a1e9edd03a044ae39b047669a2e9f623",
            "4f5dd4547a71423ca22bab6ea3e21b11",
            "4646f3eda2d34c4d92dca330d912f147"
          ]
        },
        "outputId": "ba06c26f-9621-4a33-9259-0c59ffe0281c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "215ef97e259c49ee9ff3f9597b431b68",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBu-v8elqlLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "f76cd617-e780-4e8a-9377-24d71c1e3b2f"
      },
      "source": [
        "text = train_comments.iloc[0].comment\n",
        "tokens = tokenizer.tokenize(text)\n",
        "\n",
        "# print out the list of tokens and see what we truncate\n",
        "print('==== First 512 tokens: ====\\n')\n",
        "print(wrapper.fill(str(' '.join(tokens[0:512]))))\n",
        "print('')\n",
        "print('\\n==== Remaining {:,} tokens: ====\\n'.format(len(tokens) - 512))\n",
        "print(wrapper.fill(str(' '.join(tokens[512:]))))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==== First 512 tokens: ====\n",
            "\n",
            "` - this is not ` ` creative ` ` . those are the dictionary definitions of the\n",
            "terms ` ` insurance ` ` and ` ` en ##sur ##ance ` ` as properly applied to ` `\n",
            "destruction ` ` . if you don ' t understand that , fine , legitimate criticism ,\n",
            "i ' ll write up ` ` three man cell ` ` and ` ` bounty hunter ` ` and then it\n",
            "will be easy to understand why ` ` ensured ` ` and ` ` ins ##ured ` ` are\n",
            "different - and why both differ from ` ` assured ` ` . the sentence you quote is\n",
            "absolutely neutral . you just aren ' t familiar with the underlying theory of\n",
            "strike - back ( e . g . submarines as employed in nuclear warfare ) guiding the\n",
            "insurance , nor likely the three man cell structure that kept the ira from being\n",
            "broken by the british . if that ' s my fault , fine , i can fix that to explain\n",
            ". but the ##r ' es nothing ` ` personal ` ` or ` ` creative ` ` about it . i ' m\n",
            "tired of arguing with you . re : the other article , ` ` multi - party ` ` turns\n",
            "up plenty , and there is more use of ` ` mutually ` ` than ` ` mutual ` ` . if i\n",
            "were to apply your standard i ' d be moving ` ` mutual assured destruction ` `\n",
            "to ` ` talk ` ` for not appealing to a reagan voter ' s bias ##es about its\n",
            "effectiveness , and for dropping the ` ` l ##y ` ` . there is a double standard\n",
            "in your edit ##s . if it comes from some us history book , like ` ` peace\n",
            "movement ` ` or ' m . a . d . ' as defined in 1950 , you like it , even if the\n",
            "definition is totally useless in 2002 and only of historical interest . if it\n",
            "makes any even - obvious connection or implication from the language chosen in\n",
            "multiple profession - specific terms , you consider it somehow non - neutral . .\n",
            ". gandhi thinks ` ` eye for an eye ` ` describes riots , death penalty , and war\n",
            "all at once , but you don ' t . what do you know that gandhi doesn ' t ? guess\n",
            "what : reality is not neutral . current use of terms is slightly more\n",
            "controversial . neutrality requires negotiation , and some willingness to learn\n",
            ". this is your problem not mine . you may dislike the writing , fine , that can\n",
            "be fixed . but disregard ##ing fundamental ax ##ioms of phil ##os ##phy with\n",
            "names that rec ##ur in multiple phrases , or failing to make critical\n",
            "distinctions like ' insurance ' versus ' assurance ' versus ' en ##sur ##ance '\n",
            "( which\n",
            "\n",
            "\n",
            "==== Remaining 79 tokens: ====\n",
            "\n",
            "are made in one quote by an air force general in an in - context quote ) , is\n",
            "just a di ##sser ##vic ##e to the reader . if someone comes here to research a\n",
            "topic like mad , they want some context , beyond history . if this is a history\n",
            "book , fine , it ' s a history book . but that wasn ' t what it was claimed to\n",
            "be . . . `\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlslQyjdr8z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A few ways to deal with this problem is truncation and chunking\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "input_ids = []\n",
        "lengths = []\n",
        "\n",
        "print('Tokenizing comments...')\n",
        "for sent in train_comments.comment:\n",
        "  if ((len(input_ids) % 20000) == 0):\n",
        "    print('Read {:,} comments.'.format(len(input_ids)))\n",
        "    \n",
        "  # 'encode' will:\n",
        "  # (1) tokenize the sentence\n",
        "  # (2) prepend the [CLS] token to the start\n",
        "  # (3) append the [SEP] token to the start\n",
        "  # (4) map tokens to their IDs\n",
        "  encoded_sent = tokenizer.encode(\n",
        "        sent,                      # sentence to encode\n",
        "        add_special_tokens = True, # add [CLS] and [SEP]\n",
        "        #max_length = 512,\n",
        "        #return_tensors = 'pt',\n",
        "    )\n",
        "\n",
        "  input_ids.append(encoded_sent)\n",
        "  lengths.append(len(encoded_sent))\n",
        "\n",
        "print('Done!')\n",
        "print('{:>10,} comments'.format(len(input_ids)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjMQHP4fvJkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}